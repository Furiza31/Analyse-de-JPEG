{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPEG\n",
    "## Introduction\n",
    "**J**oint **P**hotographic **E**xperts **G**roup ou **JPEG** est une norme qui définit le format d'enregistrement et l'algorithme de décodage pour une représentation numérique compressée d'une image fixe.\n",
    "La compression **JPEG** repose sur la **suppression** de **données redondantes** et **non perceptibles** dans une image.\n",
    "\n",
    "## Pourquoi est-ce intérécent de connaître comment ça fonctionnent?\n",
    "- La plus part des images de votre téléphone ou de votre caméra son enregisté dans le format JPEG.\n",
    "- environ 86% des images sur le web sont au format JPEG.\n",
    "- La plus part des vidéos utilise le principe de ce format pour être compréssée.\n",
    "\n",
    "Cette algorithme est partout dans notre vie et occupu une place importante dans celui-ci.\n",
    "\n",
    "## Globalement qu'est ce que ça fait?\n",
    "L'algorithme de compression va analyser chaque section d'une image, il va trouver et supprimer chaque pixels que nos yeux ne peuvent pas voir facilement.\n",
    "\n",
    "## Pourquoi ça marche\n",
    "Les oeils hummain ne sont pas parfait, ils ont leurs défaux. JPEG utilise ces défaux pour supprimer les informations que nos oeils on du mal à percevoir.\n",
    "Un oeils est composé de Tiges qui nous permettent de capter la luminosité mais aussi, de Cônes pour capter les couleurs (Rouge, Vers, Bleu).\n",
    "Dans chaque oeils nous avons cent million de Tiges et seulement 6 millions de Cônes.\n",
    "Nos oeils sont beacoup plus réceptif à la luminosité et à l'obscurité plus tôt que aux couleurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment ça marche ?\n",
    "### Conversion de l'espace couleur\n",
    "Une image est composé de pixels, ces pixels sont un mélange de rouge, vert et bleu allant de 0 à 255. Le mélange de ces couleur nous permet d'obtenir une couleur spécifique pour un pixel.\n",
    "\n",
    "Le processus de **conversion de l'espace couleur** prend ces trois valeurs (Rouge, Vert, Bleu) pour chaque pixel, et calcul trois nouvelle valeurs (Luminosité, Chrominance Bleu, Chrominance Rouge). Ce processus est réversible, il est appelé **YCbCr**. Durant ce processus aucune données n'est perdu, c'est juste une nouvelle façon de représenter les couleurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4979:4999:1211/142801.648117:ERROR:object_proxy.cc(577)] Failed to call method: org.freedesktop.DBus.Properties.Get: object_path= /org/freedesktop/portal/desktop: org.freedesktop.DBus.Error.InvalidArgs: L’interface « org.freedesktop.portal.FileChooser » n’existe pas\n",
      "[4979:4999:1211/142801.648161:ERROR:select_file_dialog_linux_portal.cc(285)] Failed to read portal version property\n",
      "[4979:4979:1211/142801.654282:ERROR:policy_logger.cc(156)] :components/enterprise/browser/controller/chrome_browser_cloud_management_controller.cc(161) Cloud management controller initialization aborted as CBCM is not enabled. Please use the `--enable-chrome-browser-cloud-management` command line flag to enable it if you are not using the official Google Chrome build.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouverture dans une session de navigateur existante.\n"
     ]
    }
   ],
   "source": [
    "# Ouvre le fichier image\n",
    "from PIL import Image\n",
    "\n",
    "# Ouvre le fichier image\n",
    "img = Image.open(\"image.bmp\")\n",
    "\n",
    "# Transforme l'image en tableau de pixels RGB\n",
    "pixels = img.load()\n",
    "\n",
    "# Fonction qui transforme un tuple RGB en tuple YCbCr\n",
    "def RGBtoYCbCr(RGB):\n",
    "    R, G, B = RGB\n",
    "    Y = 0.299 * R + 0.587 * G + 0.114 * B\n",
    "    Cb = -0.168736 * R - 0.331264 * G + 0.5 * B + 128\n",
    "    Cr = 0.5 * R - 0.418688 * G - 0.081312 * B + 128\n",
    "    return (Y, Cb, Cr)\n",
    "\n",
    "# Fonction qui transforme un tuple YCbCr en tuple RGB\n",
    "def YCbCrtoRGB(YCbCr):\n",
    "    Y, Cb, Cr = YCbCr\n",
    "    R = Y + 1.402 * (Cr - 128)\n",
    "    G = Y - 0.34414 * (Cb - 128) - 0.71414 * (Cr - 128)\n",
    "    B = Y + 1.772 * (Cb - 128)\n",
    "    return (R, G, B)\n",
    "\n",
    "# Affiche l'image\n",
    "img.show()\n",
    "\n",
    "# Transforme chaque pixel du tableau de de tuple RGB en tuple YCbCr\n",
    "for i in range(img.size[0]):\n",
    "    for j in range(img.size[1]):\n",
    "        YCbCr = RGBtoYCbCr(pixels[i,j])\n",
    "        pixels[i,j] = (int(YCbCr[0]), int(YCbCr[1]), int(YCbCr[2]))\n",
    "\n",
    "# Affiche l'image aprés transformation\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sous-échantillonnage de la chrominance\n",
    "Cette méthode permet par la suite de supprimer des données qui ne sont pas perceptible par nos yeux, comme nous l'avons dit plus tôt nos yeux sont movais pour detecter la couleur. Cette méthode est basé sur le fait que nos yeux sont beaucoup plus réceptif à la luminosité qu'aux couleurs.\n",
    "\n",
    "Dans cette methode nous prenons les valeurs de chrominance bleu et rouge. Par la suite nous les divisons les deux images obtenus en blocks de pixels de 2 par 2. Puis nous calculons la moyenne de chaque block pour supprimer les données redondantes pour faire en sorte que chaque valeur moyenne d'un block de 4 pixels soit la même (en occupe 1 seul). En conséquence, les informations selon lesquelles nos yeux sont incapable de percevoir sont réduites de 75%, soit 1/4 de la taille d'origine, mais la luminosité reste intacte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[5643:5729:1211/142810.689645:ERROR:object_proxy.cc(577)] Failed to call method: org.freedesktop.DBus.Properties.Get: object_path= /org/freedesktop/portal/desktop: org.freedesktop.DBus.Error.InvalidArgs: L’interface « org.freedesktop.portal.FileChooser » n’existe pas\n",
      "[5643:5729:1211/142810.689711:ERROR:select_file_dialog_linux_portal.cc(285)] Failed to read portal version property\n",
      "[5643:5643:1211/142810.695586:ERROR:policy_logger.cc(156)] :components/enterprise/browser/controller/chrome_browser_cloud_management_controller.cc(161) Cloud management controller initialization aborted as CBCM is not enabled. Please use the `--enable-chrome-browser-cloud-management` command line flag to enable it if you are not using the official Google Chrome build.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouverture dans une session de navigateur existante.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouverture dans une session de navigateur existante.\n",
      "Ouverture dans une session de navigateur existante.\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour diviser l'image en chrominance bleue et rouge\n",
    "def extract_blue_chrominance(pixel):\n",
    "    y, cb, cr = pixel\n",
    "    return (0, cb, 0)\n",
    "\n",
    "def extract_red_chrominance(pixel):\n",
    "    y, cb, cr = pixel\n",
    "    return (0, 0, cr)\n",
    "\n",
    "def extract_luminance(pixel):\n",
    "    y, cb, cr = pixel\n",
    "    return (y, 0, 0)\n",
    "\n",
    "# Fonction pour calculer la moyenne des blocs de 2x2\n",
    "def average_block(pixels, color):\n",
    "    width, height = img.size\n",
    "    for i in range(0, width - 1, 2):\n",
    "        for j in range(0, height - 1, 2):\n",
    "            # Prendre les pixels dans un bloc de 2x2\n",
    "            block = [\n",
    "                pixels[i, j],\n",
    "                pixels[i + 1, j] if i + 1 < width else pixels[i, j],\n",
    "                pixels[i, j + 1] if j + 1 < height else pixels[i, j],\n",
    "                pixels[i + 1, j + 1] if (i + 1 < width and j + 1 < height) else pixels[i, j]\n",
    "            ]\n",
    "            # Calculer la moyenne des valeurs de chrominance dans le bloc\n",
    "            avg_cb = sum(p[1] for p in block) // len(block)\n",
    "            avg_cr = sum(p[2] for p in block) // len(block)                    \n",
    "            # Mettre à jour les images de chrominance bleue et rouge\n",
    "            if color == \"blue\":\n",
    "                for x in range(min(2, width - i)):\n",
    "                    for y in range(min(2, height - j)):\n",
    "                        blue_pixels[i + x, j + y] = (0, avg_cb, 0)\n",
    "            elif color == \"red\":\n",
    "                for x in range(min(2, width - i)):\n",
    "                    for y in range(min(2, height - j)):\n",
    "                        red_pixels[i + x, j + y] = (0, 0, avg_cr)\n",
    "\n",
    "# Créez une nouvelle image pour la chrominance bleue\n",
    "blue_chrominance = Image.new(\"YCbCr\", img.size)\n",
    "blue_pixels = blue_chrominance.load()\n",
    "\n",
    "# Créez une nouvelle image pour la chrominance rouge\n",
    "red_chrominance = Image.new(\"YCbCr\", img.size)\n",
    "red_pixels = red_chrominance.load()\n",
    "\n",
    "# Créez une nouvelle image pour la luminance\n",
    "luminance = Image.new(\"YCbCr\", img.size)\n",
    "luminance_pixels = luminance.load()\n",
    "\n",
    "# Extraire la chrominance bleue, rouge et la luminance\n",
    "for i in range(img.size[0]):\n",
    "    for j in range(img.size[1]):\n",
    "        blue_pixels[i, j] = extract_blue_chrominance(pixels[i, j])\n",
    "        red_pixels[i, j] = extract_red_chrominance(pixels[i, j])\n",
    "        luminance_pixels[i, j] = extract_luminance(pixels[i, j])\n",
    "\n",
    "# Affichage des images de chrominance bleue et rouge\n",
    "blue_chrominance.show()\n",
    "red_chrominance.show()\n",
    "\n",
    "# Moyenne des blocks de 2x2\n",
    "average_block(blue_pixels, \"blue\")\n",
    "average_block(red_pixels, \"red\")\n",
    "\n",
    "# Affichage des images de chrominance bleue et rouge aprés moyenne des block de 2x2\n",
    "blue_chrominance.show()\n",
    "red_chrominance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformée en cosinus discrète et Quantification\n",
    "\n",
    "Par la suite, ces deux étapes supprime également des informations, mais elle le font en exploitant le fait que nos yeux sont pas doués pour percevoir les éléments à hautre fréquence dans les images. Mais qu'est ce que ça veut dire ?\n",
    "\n",
    "![edge](./edge.bmp)\n",
    "\n",
    "Sur cette image de l'oreil droite du tigre, nos yeux sont capable de voir les contours de l'oreil, mais pas les détails à l'intérieur de l'oreil. C'est ce que l'on appelle les éléments à haute fréquence. Les éléments à haute fréquence sont des éléments qui changent rapidement dans une image. Les éléments à basse fréquence sont des éléments qui changent lentement dans une image.\n",
    "\n",
    "La plus part des images des photographies de nature ou de paysage comportent des parties de l'image qui sont floues et la suppréssion des variations de couleurs à haute fraiquence pour créer des textures plus douces ne sont pas perceptible par nos yeux. Alors, comment l'algorithme JPEG exploite les nuance de l'oeil humain pour supprimer les éléments à haute fréquence ?\n",
    "\n",
    "L'algorithme JPEG utilise une technique appelée **Transformée en cosinus discrète** ou **DCT**. Cette technique prend un block de 8 par 8 pixels et le transforme en un tableau de 8 par 8 valeurs. Chaque valeur représente la quantité de chaque fréquence dans le block. La valeur en haut à gauche représente la fréquence la plus basse et la valeur en bas à droite représente la fréquence la plus haute. Nous enlevons 128 à chaque valeur pour que les valeurs soient comprises entre -128 et 127. -128 représente la fréquence la plus basse et 127 la fréquence la plus haute.\n",
    "\n",
    "![dct](./dct.png)\n",
    "\n",
    "Dans cette illustration de la DCT, les zones sombres représentent les basses fréquences et les zones claires les hautes fréquences. L'information relative aux hautes fréquences, souvent négligeable pour la perception humaine, est donc regroupée vers les coins de la matrice, tandis que l'information des basses fréquences, plus cruciale pour la perception, est située près du coin supérieur gauche.\n",
    "Prenons par exemple le deuxième carré en haut à gauche vers le bas. Plus la valeur de celui-ci sera haute, plus il y auras de dégradé de blanc vers le noir dans l'image. Si la valeur est basse, il y auras moins de dégradé de blanc vers le noir dans l'image. L'ensemble de ces valeurs nous permettent de reconstruire l'image.\n",
    "\n",
    "Cette concentration des informations selon les capacités de perception humaine permet une réduction significative de la taille des données sans altérer sensiblement la qualité visuelle perçue.\n",
    "\n",
    "Voici la formule de la DCT:\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/e06f6ee04c9c879a283edcbb7b1fc18b86fcec5b\" alt=\"DCT\"/>\n",
    "\n",
    "u est la fréquence spatiale horizontale, pour les entiers 0 ≤ u < 8\n",
    "\n",
    "v est la fréquence spatiale verticale, pour les entiers 0 ≤ v < 8\n",
    "\n",
    "x et y sont les coordonnées horizontales et verticales du pixel, pour 0 ≤ x < 8 et 0 ≤ y < 8\n",
    "\n",
    "Le processus s'applique sur la chrominance bleu et rouge, mais aussi sur la luminosité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCT de la luminance\n",
      "576.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "luminance_minus_128 = []\n",
    "blue_minus_128 = []\n",
    "red_minus_128 = []\n",
    "\n",
    "# Soustraction de 128 pour chaque pixel\n",
    "for i in range(img.size[0]):\n",
    "    luminance_minus_128.append([])\n",
    "    blue_minus_128.append([])\n",
    "    red_minus_128.append([])\n",
    "    for j in range(img.size[1]):\n",
    "        luminance_minus_128[i].append(luminance_pixels[i, j][0] - 128)\n",
    "        blue_minus_128[i].append(blue_pixels[i, j][1] - 128)\n",
    "        red_minus_128[i].append(red_pixels[i, j][2] - 128)\n",
    "\n",
    "# Fonction pour calculer le coefficient alpha\n",
    "def alpha(u):\n",
    "    return 1 / math.sqrt(2) if u == 0 else 1\n",
    "\n",
    "# Appliquer la transformation en cosinus discret (DCT) sur un bloc de 8x8\n",
    "def apply_dct(block):\n",
    "    dct_block = [[0 for _ in range(8)] for _ in range(8)]  # Initialisation d'une matrice pour stocker les résultats de la DCT\n",
    "    for x in range(8):\n",
    "        for y in range(8):\n",
    "            sum_val = 0\n",
    "            # Calcul de la DCT pour chaque élément du bloc 8x8\n",
    "            for i in range(8):\n",
    "                for j in range(8):\n",
    "                    sum_val += block[i][j] * math.cos(((2 * i + 1) * x * math.pi) / 16) * math.cos(((2 * j + 1) * y * math.pi) / 16)\n",
    "            # Stockage du résultat dans la matrice de la DCT après l'application des coefficients alpha\n",
    "            dct_block[x][y] = round(sum_val * (1 / 4 * alpha(x) * alpha(y)), 2)\n",
    "    return dct_block\n",
    "\n",
    "# Appliquer la transformation en cosinus discret (DCT) sur toute la matrice\n",
    "def discrete_cosine_transform(matrix):\n",
    "    width = len(matrix)\n",
    "    height = len(matrix[0])\n",
    "\n",
    "    dct = []  # Initialisation d'une liste pour stocker les blocs DCT\n",
    "    for u in range(0, width, 8):\n",
    "        dct.append([])\n",
    "        for v in range(0, height, 8):\n",
    "            # Création de blocs 8x8 à partir de la matrice d'entrée\n",
    "            block = [[matrix[x][y] if x < width and y < height else 0 for y in range(v, v + 8)] for x in range(u, u + 8)]\n",
    "            # Application de la DCT sur chaque bloc 8x8\n",
    "            dct_block = apply_dct(block)\n",
    "            # Stockage du bloc DCT dans la liste\n",
    "            dct[-1].append(dct_block)\n",
    "\n",
    "    # Réorganisation des coefficients DCT dans une seule liste\n",
    "    dct = [[dct[u][v][x][y] for v in range(len(dct[u])) for y in range(8)] for u in range(len(dct)) for x in range(8)]\n",
    "    return dct\n",
    "\n",
    "            \n",
    "\n",
    "# DCT de la luminance\n",
    "luminance_dct = discrete_cosine_transform(luminance_minus_128)\n",
    "# DCT de la chrominance bleue\n",
    "blue_dct = discrete_cosine_transform(blue_minus_128)\n",
    "# DCT de la chrominance rouge\n",
    "red_dct = discrete_cosine_transform(red_minus_128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ce stade, nous avons la luminosité, la chrominance bleu ainsi que la chrominance rouge.\n",
    "Nous avons aussi créé une variable qui représente les valeurs du dct sous forme matricielle pour chaque chrominance et luminosité.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longueur d'exécution et codage de Huffman"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
