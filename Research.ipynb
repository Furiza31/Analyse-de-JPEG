{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPEG\n",
    "\n",
    "Hugo Wendjaneh - Vincent Miqueu-Denjean\n",
    "\n",
    "BUT3 - Groupe 1\n",
    "\n",
    "## Introduction\n",
    "**J**oint **P**hotographic **E**xperts **G**roup ou **JPEG** est une norme qui définit le format d'enregistrement et l'algorithme de décodage pour une représentation numérique compressée d'une image fixe.\n",
    "La compression **JPEG** repose sur la **suppression** de **données redondantes** et **non perceptibles** dans une image.\n",
    "\n",
    "## Pourquoi est-ce intéressant de connaître comment ça fonctionne  ?\n",
    "- La plupart des images de votre téléphone ou de votre caméra sont enregistrées dans le format JPEG.\n",
    "— Environ 86% des images sur le web sont au format JPEG.\n",
    "- La plupart des vidéos utilisent le principe de ce format pour être compressées.\n",
    "\n",
    "Cet algorithme est partout dans notre vie et occupe une place importante dans celui-ci.\n",
    "\n",
    "## Globalement, qu'est-ce que ça fait ?\n",
    "L'algorithme de compression va analyser chaque section d'une image, il va trouver et supprimer chaque pixel que nos yeux ne peuvent pas voir facilement.\n",
    "\n",
    "## Pourquoi ça marche\n",
    "Les œils humains ne sont pas parfaits, ils ont leurs défauts. JPEG utilise ces défauts pour supprimer les informations que nos yeux ont du mal à percevoir.\n",
    "Un œil est composé de Tiges qui nous permettent de capter la luminosité, mais aussi, de Cônes pour capter les couleurs (Rouge, Vers, Bleu).\n",
    "Dans chaque œil, nous avons cent millions de Tiges et seulement 6 millions de Cônes.\n",
    "Nos yeux sont beaucoup plus réceptifs à la luminosité et à l'obscurité plutot qu'aux couleurs.\n",
    "\n",
    "## Comment ça marche ?\n",
    "### Conversion de l'espace couleur\n",
    "Une image est composée de pixels, ces pixels sont un mélange de rouge, vert et bleu allant de 0 à 255. Le mélange de ces couleurs nous permet d'obtenir une couleur spécifique pour un pixel.\n",
    "\n",
    "Le processus de **conversion de l'espace couleur** prend ces trois valeurs (Rouge, Vert, Bleu) pour chaque pixel et calcule trois nouvelles valeurs (Luminosité, Chrominance Bleu, Chrominance Rouge). Ce processus est réversible, il est appelé **YCbCr**. Durant ce processus, aucune donnée n'est perdue, c'est juste une nouvelle façon de représenter les couleurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3084:3103:1223/191443.913540:ERROR:object_proxy.cc(577)] Failed to call method: org.freedesktop.DBus.Properties.Get: object_path= /org/freedesktop/portal/desktop: org.freedesktop.DBus.Error.InvalidArgs: L’interface « org.freedesktop.portal.FileChooser » n’existe pas\n",
      "[3084:3103:1223/191443.913594:ERROR:select_file_dialog_linux_portal.cc(285)] Failed to read portal version property\n",
      "[3084:3084:1223/191443.916176:ERROR:policy_logger.cc(156)] :components/enterprise/browser/controller/chrome_browser_cloud_management_controller.cc(161) Cloud management controller initialization aborted as CBCM is not enabled. Please use the `--enable-chrome-browser-cloud-management` command line flag to enable it if you are not using the official Google Chrome build.\n"
     ]
    }
   ],
   "source": [
    "# Ouvre le fichier image\n",
    "from PIL import Image\n",
    "\n",
    "# Ouvre le fichier image\n",
    "img = Image.open(\"image.bmp\")\n",
    "\n",
    "# Transforme l'image en tableau de pixels RGB\n",
    "pixels = img.load()\n",
    "\n",
    "# Fonction qui transforme un tuple RGB en tuple YCbCr\n",
    "def RGBtoYCbCr(RGB):\n",
    "    R, G, B = RGB\n",
    "    Y = 0.299 * R + 0.587 * G + 0.114 * B\n",
    "    Cb = -0.168736 * R - 0.331264 * G + 0.5 * B + 128\n",
    "    Cr = 0.5 * R - 0.418688 * G - 0.081312 * B + 128\n",
    "    return (Y, Cb, Cr)\n",
    "\n",
    "# Fonction qui transforme un tuple YCbCr en tuple RGB\n",
    "def YCbCrtoRGB(YCbCr):\n",
    "    Y, Cb, Cr = YCbCr\n",
    "    R = Y + 1.402 * (Cr - 128)\n",
    "    G = Y - 0.34414 * (Cb - 128) - 0.71414 * (Cr - 128)\n",
    "    B = Y + 1.772 * (Cb - 128)\n",
    "    return (R, G, B)\n",
    "\n",
    "# Affiche l'image\n",
    "img.show()\n",
    "\n",
    "# Transforme chaque pixel du tableau de de tuple RGB en tuple YCbCr\n",
    "for i in range(img.size[0]):\n",
    "    for j in range(img.size[1]):\n",
    "        YCbCr = RGBtoYCbCr(pixels[i,j])\n",
    "        pixels[i,j] = (int(YCbCr[0]), int(YCbCr[1]), int(YCbCr[2]))\n",
    "\n",
    "# Affiche l'image après transformation\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sous-échantillonnage de la chrominance\n",
    "Cette méthode permet par la suite de supprimer des données qui ne sont pas perceptibles par nos yeux, comme nous l'avons dit plus tôt nos yeux sont mauvais pour détecter la couleur. Cette méthode est basée sur le fait que nos yeux sont beaucoup plus réceptifs à la luminosité qu'aux couleurs.\n",
    "\n",
    "Dans cette méthode, nous prenons les valeurs de chrominance bleue et rouge. Par la suite, nous divisons les deux images obtenues en blocs de pixels de 2 par 2. Puis, nous calculons la moyenne de chaque bloc pour supprimer les données redondantes pour faire en sorte que chaque valeur moyenne d'un bloc de quatre pixels soit la même (en occupe un seul). En conséquence, les informations selon lesquelles nos yeux sont incapables de percevoir sont réduites de 75%, soit 1/4 de la taille d'origine, mais la luminosité reste intacte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouverture dans une session de navigateur existante.\n",
      "Ouverture dans une session de navigateur existante.\n",
      "Ouverture dans une session de navigateur existante.\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour diviser l'image en chrominance bleue et rouge\n",
    "def extract_blue_chrominance(pixel):\n",
    "    y, cb, cr = pixel\n",
    "    return (0, cb, 0)\n",
    "\n",
    "def extract_red_chrominance(pixel):\n",
    "    y, cb, cr = pixel\n",
    "    return (0, 0, cr)\n",
    "\n",
    "def extract_luminance(pixel):\n",
    "    y, cb, cr = pixel\n",
    "    return (y, 0, 0)\n",
    "\n",
    "# Fonction pour calculer la moyenne des blocs de 2x2\n",
    "def average_block(pixels, color):\n",
    "    width, height = img.size\n",
    "    for i in range(0, width - 1, 2):\n",
    "        for j in range(0, height - 1, 2):\n",
    "            # Prendre les pixels dans un bloc de 2x2\n",
    "            block = [\n",
    "                pixels[i, j],\n",
    "                pixels[i + 1, j] if i + 1 < width else pixels[i, j],\n",
    "                pixels[i, j + 1] if j + 1 < height else pixels[i, j],\n",
    "                pixels[i + 1, j + 1] if (i + 1 < width and j + 1 < height) else pixels[i, j]\n",
    "            ]\n",
    "            # Calculer la moyenne des valeurs de chrominance dans le bloc\n",
    "            avg_cb = sum(p[1] for p in block) // len(block)\n",
    "            avg_cr = sum(p[2] for p in block) // len(block)                    \n",
    "            # Mettre à jour les images de chrominance bleue et rouge\n",
    "            if color == \"blue\":\n",
    "                for x in range(min(2, width - i)):\n",
    "                    for y in range(min(2, height - j)):\n",
    "                        blue_pixels[i + x, j + y] = (0, avg_cb, 0)\n",
    "            elif color == \"red\":\n",
    "                for x in range(min(2, width - i)):\n",
    "                    for y in range(min(2, height - j)):\n",
    "                        red_pixels[i + x, j + y] = (0, 0, avg_cr)\n",
    "\n",
    "# Créer une nouvelle image pour la chrominance bleue\n",
    "blue_chrominance = Image.new(\"YCbCr\", img.size)\n",
    "blue_pixels = blue_chrominance.load()\n",
    "\n",
    "# Créer une nouvelle image pour la chrominance rouge\n",
    "red_chrominance = Image.new(\"YCbCr\", img.size)\n",
    "red_pixels = red_chrominance.load()\n",
    "\n",
    "# Créer une nouvelle image pour la luminance\n",
    "luminance = Image.new(\"YCbCr\", img.size)\n",
    "luminance_pixels = luminance.load()\n",
    "\n",
    "# Extraire la chrominance bleue, rouge et la luminance\n",
    "for i in range(img.size[0]):\n",
    "    for j in range(img.size[1]):\n",
    "        blue_pixels[i, j] = extract_blue_chrominance(pixels[i, j])\n",
    "        red_pixels[i, j] = extract_red_chrominance(pixels[i, j])\n",
    "        luminance_pixels[i, j] = extract_luminance(pixels[i, j])\n",
    "\n",
    "# Affichage des images de chrominance bleue et rouge\n",
    "blue_chrominance.show()\n",
    "red_chrominance.show()\n",
    "\n",
    "# Moyenne des blocks de 2x2\n",
    "average_block(blue_pixels, \"blue\")\n",
    "average_block(red_pixels, \"red\")\n",
    "\n",
    "# Affichage des images de chrominance bleue et rouge aprés moyenne des block de 2x2\n",
    "blue_chrominance.show()\n",
    "red_chrominance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformées en cosinus discrète et Quantification\n",
    "\n",
    "Par la suite, ces deux étapes suppriment également des informations, mais elles le font en exploitant le fait que nos yeux ne sont pas doués pour percevoir les éléments à autre fréquence dans les images. Mais qu'est-ce que ça veut dire ?\n",
    "\n",
    "![edge](./edge.bmp)\n",
    "\n",
    "Sur cette image de l'oreille droite du tigre, nos yeux sont capables de voir les contours de l'oreille, mais pas les détails à l'intérieur de l'oreille. C'est ce que l'on appelle les éléments à haute fréquence. Les éléments à haute fréquence sont des éléments qui changent rapidement dans une image. Les éléments à basse fréquence sont des éléments qui changent lentement dans une image. Nous allons donc utiliser cette information, tromper nos yeux et supprimer les éléments à haute fréquence.\n",
    "\n",
    "La plupart des images des photographies de nature ou de paysage comportent des parties de l'image qui sont floues et la suppression des variations de couleurs à haute fréquence pour créer des textures plus douces ne sont pas perceptibles par nos yeux. Alors, comment l'algorithme JPEG exploite les nuances de l'œil humain pour supprimer les éléments à haute fréquence ?\n",
    "\n",
    "L'algorithme JPEG utilise une technique appelée **Transformée en cosinus discrète** ou **DCT**. Cette technique prend un bloc de 8 par 8 pixels et le transforme en un tableau de 8 par 8 valeurs. Chaque valeur représente la quantité de chaque fréquence dans le bloc. La valeur en haut à gauche représente la fréquence la plus basse et la valeur en bas à droite représente la fréquence la plus haute. Nous enlevons 128 à chaque valeur pour que les valeurs soient comprises entre -128 et 127. -128 représente la fréquence la plus basse et 127 la fréquence la plus haute.\n",
    "\n",
    "![dct](./dct.png)\n",
    "\n",
    "Dans cette illustration de la DCT, les zones sombres représentent les basses fréquences et les zones claires les hautes fréquences. L'information relative aux hautes fréquences, souvent négligeable pour la perception humaine, est donc regroupée vers les coins de la matrice, tandis que l'information des basses fréquences, plus cruciale pour la perception, est située près du coin supérieur gauche.\n",
    "Prenons par exemple le deuxième carré en haut à gauche vers le bas. Plus la valeur de celui-ci sera haute, plus il y aura de dégradé vers le bas de blanc à noir dans l'image. Si la valeur est basse, il y aura un dégradé vers le haut de noir à blanc dans l'image. L'ensemble de ces valeurs nous permet de reconstruire l'image.\n",
    "\n",
    "Voici la formule de la DCT :\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/e06f6ee04c9c879a283edcbb7b1fc18b86fcec5b\" alt=\"DCT\" style=\"background-color: white; padding: 5px; box-sizing: border-box; border-radius: 5px;\"/>\n",
    "\n",
    "u est la fréquence spatiale horizontale, pour les entiers 0 ≤ u < 8\n",
    "\n",
    "v est la fréquence spatiale verticale, pour les entiers 0 ≤ v < 8\n",
    "\n",
    "x et y sont les coordonnées horizontales et verticales du pixel, pour 0 ≤ x < 8 et 0 ≤ y < 8\n",
    "\n",
    "Le processus s'applique sur la chrominance bleue et rouge, mais aussi sur la luminosité.\n",
    "\n",
    "Les cosinus sont utilisés, car ils sont orthogonaux, ce qui signifie que les valeurs de la DCT sont indépendantes les unes des autres. Il permet de décomposer des signaux en une série de fonctions orthogonales.\n",
    "\n",
    "Il faut savoir que lorsque l'on réapplique cette formule, nous obtenons les mêmes valeurs que l'original. Cette formule est donc réversible.\n",
    "\n",
    "Nous allons utiliser le **DCT** pour transformer l'image de pixels en une image de fréquences. Nous allons ensuite utiliser la **Quantification** pour supprimer les fréquences que nos yeux ne peuvent pas voir facilement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouverture dans une session de navigateur existante.\n",
      "Ouverture dans une session de navigateur existante.\n",
      "Exemple d'une ligne de de pixel sous forme de fréquence de la luminance: \n",
      "[576.0, -7.65, -1.71, 2.43, -2.0, -0.63, 0.44, 0.9, 594.62, -4.19, 1.51, -4.14, 0.38, -0.14, 0.05, -0.77, 606.25, 8.65, -11.52, 0.59, -4.0, 0.41, -0.37, -0.07, 406.75, 95.15, -11.96, 5.73, -1.25, 2.09, 1.17, 0.51, 75.37, 70.37, 9.36, 8.97, 3.88, 0.27, 0.05, 0.49, -99.0, 49.26, -5.19, 3.42, 1.5, 3.0, 0.53, 1.03, -361.12, 83.9, 2.65, 6.0, 2.12, 3.8, -1.77, 0.29, -551.75, 28.16, 1.63, 3.88, -4.75, -0.94, 0.68, 0.44, -559.0, -29.02, 7.23, -3.72, 2.0, -2.1, -0.83, 1.04, -291.5, -124.33, 4.18, -7.56, 3.5, 0.21, 7.47, -1.16, 129.37, -85.19, -45.69, 5.59, -11.87, 0.56, -6.11, -1.25, 91.5, -93.1, 73.4, 17.74, 13.5, 2.74, 0.17, 0.43, 162.75, 129.27, -3.55, -7.41, -3.25, -0.87, -5.3, 0.33, -64.87, 3.4, 7.6, 7.21, 2.37, -0.04, 1.04, -0.56, -76.62, 22.93, -5.84, 1.39, -3.37, 0.11, -5.29, -0.1, -251.87, 58.88, 7.66, 11.43, -1.38, 6.8, -6.01, 0.19, -533.5, 29.93, 43.31, 7.69, 8.75, -0.3, -0.62, 0.62, -429.87, -1.82, -23.8, -7.71, -5.88, -2.76, -0.29, -0.86, -462.25, -4.82, 13.79, -10.3, 3.25, -2.9, -0.03, 0.25, -165.37, -141.04, -13.07, 7.4, -6.62, 2.82, 0.14, -1.02, -31.12, -9.0, 8.32, 2.05, 2.37, 4.5, -1.15, 0.14, 37.87, -74.51, 26.53, 5.67, -0.38, -2.86, -0.3, -0.27, 151.75, 76.68, -58.99, 21.21, -11.5, 5.98, -5.87, 0.02, -289.75, 33.4, 21.18, 5.87, 11.0, 0.74, 4.76, -1.11, -201.75, -34.86, -10.87, -6.17, -3.5, -3.47, -0.1, -0.61, -166.25, 4.79, 0.37, -3.32, -2.0, -3.36, -0.42, -0.37, -254.0, 49.6, 4.13, -2.71, 3.5, 0.61, 0.18, -0.34, -261.12, -9.06, 1.74, -11.98, -2.13, -2.78, -0.04, -0.62, -68.12, -88.56, 1.57, -6.75, 0.12, -3.53, 0.84, 0.16, 250.5, -78.8, -10.67, -6.24, 4.25, -0.09, 0.36, -1.04, 404.62, -2.23, -6.09, -5.09, -1.37, -3.62, 1.3, -0.26, 412.37, 63.17, -27.86, 5.08, -2.62, -5.87, -6.18, 0.03, 179.62, 35.84, 8.34, 0.47, -0.12, 2.78, 0.2, 0.2, 112.25, -2.77, 16.94, -2.67, 3.75, -2.63, -0.25, 0.17, 315.25, -108.18, 4.3, -4.32, 0.0, 2.48, 5.8, 0.69, 542.25, -9.57, -14.89, 1.7, -6.75, -1.5, -6.55, -0.18, 507.25, 4.83, 10.31, 5.35, 0.25, 1.35, 0.06, -0.21, 570.12, -28.01, 0.18, -1.15, -1.12, -3.37, 1.41, -0.56, 641.5, -4.28, -7.72, -3.76, 3.75, -1.46, -4.92, 0.04, 662.5, -2.39, -0.0, 2.3, -4.0, 0.3, -0.0, -0.44, 673.62, 1.73, -3.84, -0.26, -2.87, -0.9, -0.44, 0.45, 443.87, 299.75, -223.25, 118.19, -35.87, -2.27, 11.43, -8.89, -610.5, 14.86, 4.62, 7.68, 2.25, 2.79, 5.93, 0.61, -632.5, 1.3, -2.37, -1.97, 4.0, -0.07, 0.17, 0.23, -633.75, -1.0, 2.33, -0.62, 3.5, -1.2, 0.39, 0.22, -139.0, -496.04, 144.71, 56.12, -67.0, 15.68, 10.96, -8.29, 608.25, -2.49, 8.0, -0.76, -4.5, -3.86, -6.83, -0.45, 643.87, -5.67, -9.3, -1.91, -1.62, 0.41, 0.74, 1.02, 647.12, 5.89, 0.03, -1.81, 2.13, -0.54, 0.39, -0.42, 651.75, 1.53, -6.5, -3.6, -0.25, 0.07, -0.01, 0.24, 633.75, 4.93, -11.95, 6.27, -1.75, 0.3, 5.76, 0.2, 603.12, -2.78, 2.66, -0.06, 0.13, 0.56, -0.43, -0.04, 594.5, 4.75, 3.94, 4.17, 6.0, -2.44, -0.28, -0.24, 590.0, -0.77, 2.26, 4.12, -1.25, 0.21, 6.1, 0.22, 603.75, -6.94, 2.37, 4.76, -0.25, 0.54, -0.17, 0.35, 75.62, 104.89, 98.81, 88.93, 75.62, 59.42, 40.93, 20.86]\n",
      "PS: Nous avons arrondis les valeurs pour une meilleur lisibilité\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "luminance_minus_128 = []\n",
    "blue_minus_128 = []\n",
    "red_minus_128 = []\n",
    "\n",
    "# Sous traction de 128 pour chaque pixel\n",
    "for i in range(img.size[0]):\n",
    "    luminance_minus_128.append([])\n",
    "    blue_minus_128.append([])\n",
    "    red_minus_128.append([])\n",
    "    for j in range(img.size[1]):\n",
    "        luminance_minus_128[i].append(luminance_pixels[i, j][0] - 128)\n",
    "        blue_minus_128[i].append(blue_pixels[i, j][1] - 128)\n",
    "        red_minus_128[i].append(red_pixels[i, j][2] - 128)\n",
    "\n",
    "# Fonction pour calculer le coefficient alpha\n",
    "def alpha(u):\n",
    "    return 1 / math.sqrt(2) if u == 0 else 1\n",
    "\n",
    "# Appliquer la transformation en cosinus discret (DCT) sur un bloc de 8x8\n",
    "def apply_dct(block):\n",
    "    dct_block = [[0 for _ in range(8)] for _ in range(8)]  # Initialisation d'une matrice pour stocker les résultats de la DCT\n",
    "    for x in range(8):\n",
    "        for y in range(8):\n",
    "            sum_val = 0\n",
    "            # Calcul de la DCT pour chaque élément du bloc 8x8\n",
    "            for i in range(8):\n",
    "                for j in range(8):\n",
    "                    sum_val += block[i][j] * math.cos(((2 * i + 1) * x * math.pi) / 16) * math.cos(((2 * j + 1) * y * math.pi) / 16)\n",
    "            # Stockage du résultat dans la matrice de la DCT après l'application des coefficients alpha\n",
    "            dct_block[x][y] = round(sum_val * (1 / 4 * alpha(x) * alpha(y)), 2)\n",
    "    return dct_block\n",
    "\n",
    "# Appliquer la transformation en cosinus discret (DCT) sur toute la matrice\n",
    "def discrete_cosine_transform(matrix):\n",
    "    width = len(matrix)\n",
    "    height = len(matrix[0])\n",
    "\n",
    "    dct = []  # Initialisation d'une liste pour stocker les blocs DCT\n",
    "    for u in range(0, width, 8):\n",
    "        dct.append([])\n",
    "        for v in range(0, height, 8):\n",
    "            # Création de blocs 8x8 à partir de la matrice d'entrée\n",
    "            block = [[matrix[x][y] if x < width and y < height else 0 for y in range(v, v + 8)] for x in range(u, u + 8)]\n",
    "            # Application de la DCT sur chaque bloc 8x8\n",
    "            dct_block = apply_dct(block)\n",
    "            # Stockage du bloc DCT dans la liste\n",
    "            dct[-1].append(dct_block)\n",
    "\n",
    "    # Réorganisation des coefficients DCT dans une seule liste\n",
    "    dct = [[dct[u][v][x][y] for v in range(len(dct[u])) for y in range(8)] for u in range(len(dct)) for x in range(8)]\n",
    "    return dct\n",
    "\n",
    "            \n",
    "\n",
    "# DCT de la luminance\n",
    "luminance_dct = discrete_cosine_transform(luminance_minus_128)\n",
    "# DCT de la chrominance bleue\n",
    "blue_dct = discrete_cosine_transform(blue_minus_128)\n",
    "# DCT de la chrominance rouge\n",
    "red_dct = discrete_cosine_transform(red_minus_128)\n",
    "\n",
    "print(\"Exemple d'une ligne de de pixel sous forme de fréquence de la luminance: \")\n",
    "print(luminance_dct[0])\n",
    "print(\"PS: Nous avons arrondis les valeurs pour une meilleur lisibilité\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: yellow; color: black; padding: 5px; border-radius: 5px; box-sizing: border-box;\">PS : Le programme ci-dessus n'est pas optimisé, en revanche, il est plus facile à comprendre. Nous aurions pu faire moins de boucles et stocker les valeurs des cosinus dans un tableau pour éviter de les recalculer à chaque fois.</div>\n",
    "\n",
    "À ce stade, nous avons créé une variable qui représente les valeurs du DCT sous forme matricielle pour chaque chrominance et luminosité.\n",
    "\n",
    "Maintenant, nous devons appliquer la **Quantification** sur les valeurs du DCT pour chaque chrominance et luminosité.\n",
    "La **Quantification** est une technique qui permet de supprimer les fréquences que nos yeux ne peuvent pas voir facilement.\n",
    "\n",
    "Il existe plusieurs matrices pour la **Quantification**. Ces matrices définissent le niveau de compression de l'image. Plus cette matrice va permettre d'avoir des 0, plus l'image sera compressée, et moins la qualité de l'image sera bonne.\n",
    "\n",
    "Voici la matrice qui permet de faire une compression de 50% comme fourni par la norme JPEG :\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>16</td>\n",
    "        <td>11</td>\n",
    "        <td>10</td>\n",
    "        <td>16</td>\n",
    "        <td>24</td>\n",
    "        <td>40</td>\n",
    "        <td>51</td>\n",
    "        <td>61</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>12</td>\n",
    "        <td>12</td>\n",
    "        <td>14</td>\n",
    "        <td>19</td>\n",
    "        <td>26</td>\n",
    "        <td>58</td>\n",
    "        <td>60</td>\n",
    "        <td>55</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>14</td>\n",
    "        <td>13</td>\n",
    "        <td>16</td>\n",
    "        <td>24</td>\n",
    "        <td>40</td>\n",
    "        <td>57</td>\n",
    "        <td>69</td>\n",
    "        <td>56</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>14</td>\n",
    "        <td>17</td>\n",
    "        <td>22</td>\n",
    "        <td>29</td>\n",
    "        <td>51</td>\n",
    "        <td>87</td>\n",
    "        <td>80</td>\n",
    "        <td>62</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>18</td>\n",
    "        <td>22</td>\n",
    "        <td>37</td>\n",
    "        <td>56</td>\n",
    "        <td>68</td>\n",
    "        <td>109</td>\n",
    "        <td>103</td>\n",
    "        <td>77</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>24</td>\n",
    "        <td>35</td>\n",
    "        <td>55</td>\n",
    "        <td>64</td>\n",
    "        <td>81</td>\n",
    "        <td>104</td>\n",
    "        <td>113</td>\n",
    "        <td>92</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>49</td>\n",
    "        <td>64</td>\n",
    "        <td>78</td>\n",
    "        <td>87</td>\n",
    "        <td>103</td>\n",
    "        <td>121</td>\n",
    "        <td>120</td>\n",
    "        <td>101</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>72</td>\n",
    "        <td>92</td>\n",
    "        <td>95</td>\n",
    "        <td>98</td>\n",
    "        <td>112</td>\n",
    "        <td>100</td>\n",
    "        <td>103</td>\n",
    "        <td>99</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Pour effectuer la **Quantification**, nous prenons toujours de bloc de 8 par 8 pixels. Nous divisons les valeurs du DCT par les valeurs de la matrice de **Quantification**. Nous arrondissons les valeurs obtenues à l'entier le plus proche. Nous obtenons ainsi une nouvelle matrice de 8 par 8 valeurs. Nous allons ensuite utiliser cette matrice pour reconstruire l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple d'une ligne de de pixel sous forme de fréquence de la luminance aprés quantification: \n",
      "[36, -1, 0, 0, 0, 0, 0, 0, 37, 0, 0, 0, 0, 0, 0, 0, 38, 1, -1, 0, 0, 0, 0, 0, 25, 9, -1, 0, 0, 0, 0, 0, 5, 6, 1, 1, 0, 0, 0, 0, -6, 4, -1, 0, 0, 0, 0, 0, -23, 8, 0, 0, 0, 0, 0, 0, -34, 3, 0, 0, 0, 0, 0, 0, -35, -3, 1, 0, 0, 0, 0, 0, -18, -11, 0, 0, 0, 0, 0, 0, 8, -8, -5, 0, 0, 0, 0, 0, 6, -8, 7, 1, 1, 0, 0, 0, 10, 12, 0, 0, 0, 0, 0, 0, -4, 0, 1, 0, 0, 0, 0, 0, -5, 2, -1, 0, 0, 0, 0, 0, -16, 5, 1, 1, 0, 0, 0, 0, -33, 3, 4, 0, 0, 0, 0, 0, -27, 0, -2, 0, 0, 0, 0, 0, -29, 0, 1, -1, 0, 0, 0, 0, -10, -13, -1, 0, 0, 0, 0, 0, -2, -1, 1, 0, 0, 0, 0, 0, 2, -7, 3, 0, 0, 0, 0, 0, 9, 7, -6, 1, 0, 0, 0, 0, -18, 3, 2, 0, 0, 0, 0, 0, -13, -3, -1, 0, 0, 0, 0, 0, -10, 0, 0, 0, 0, 0, 0, 0, -16, 5, 0, 0, 0, 0, 0, 0, -16, -1, 0, -1, 0, 0, 0, 0, -4, -8, 0, 0, 0, 0, 0, 0, 16, -7, -1, 0, 0, 0, 0, 0, 25, 0, -1, 0, 0, 0, 0, 0, 26, 6, -3, 0, 0, 0, 0, 0, 11, 3, 1, 0, 0, 0, 0, 0, 7, 0, 2, 0, 0, 0, 0, 0, 20, -10, 0, 0, 0, 0, 0, 0, 34, -1, -1, 0, 0, 0, 0, 0, 32, 0, 1, 0, 0, 0, 0, 0, 36, -3, 0, 0, 0, 0, 0, 0, 40, 0, -1, 0, 0, 0, 0, 0, 41, 0, 0, 0, 0, 0, 0, 0, 42, 0, 0, 0, 0, 0, 0, 0, 28, 27, -22, 7, -1, 0, 0, 0, -38, 1, 0, 0, 0, 0, 0, 0, -40, 0, 0, 0, 0, 0, 0, 0, -40, 0, 0, 0, 0, 0, 0, 0, -9, -45, 14, 4, -3, 0, 0, 0, 38, 0, 1, 0, 0, 0, 0, 0, 40, -1, -1, 0, 0, 0, 0, 0, 40, 1, 0, 0, 0, 0, 0, 0, 41, 0, -1, 0, 0, 0, 0, 0, 40, 0, -1, 0, 0, 0, 0, 0, 38, 0, 0, 0, 0, 0, 0, 0, 37, 0, 0, 0, 0, 0, 0, 0, 37, 0, 0, 0, 0, 0, 0, 0, 38, -1, 0, 0, 0, 0, 0, 0, 5, 10, 10, 6, 3, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "quantization_table_fifty_percent = [\n",
    "    [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "    [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "    [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "    [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "    [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "    [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "    [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "    [72, 92, 95, 98, 112, 100, 103, 99]\n",
    "]\n",
    "\n",
    "def quantize(dct, quantization_table):\n",
    "    quantized_dct = []\n",
    "    for i in range(len(dct)):\n",
    "        quantized_dct.append([])\n",
    "        for j in range(len(dct[i])):\n",
    "            # Division de chaque coefficient DCT par le coefficient de quantification correspondant\n",
    "            quantized_dct[i].append(round(dct[i][j] / quantization_table[i % 8][j % 8]))\n",
    "    return quantized_dct\n",
    "\n",
    "luminance_quantization = quantize(luminance_dct, quantization_table_fifty_percent)\n",
    "blue_quantization = quantize(blue_dct, quantization_table_fifty_percent)\n",
    "red_quantization = quantize(red_dct, quantization_table_fifty_percent)\n",
    "\n",
    "print(\"Exemple d'une ligne de de pixel sous forme de fréquence de la luminance aprés quantification: \")\n",
    "print(luminance_quantization[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez voir que les valeurs de la matrice de **Quantification** sont plus grandes dans le coin supérieur gauche et plus petites dans les coins inférieurs droits. Cela signifie que les fréquences basses sont plus susceptibles d'être conservées que les fréquences élevées. Cela permet donc de supprimer de l'information que nos yeux ne peuvent pas voir facilement.\n",
    "\n",
    "Nous allons par la suite pouvoir simplement recoder cette image en marquant non pas chaque case de la matrice, mais plus tôt les cases de la matrice et combien de fois, elles se répètent. (Run length encoding)\n",
    "\n",
    "Exemple:\n",
    "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1] => (1, 10) car 1 se répète 10 fois.\n",
    "\n",
    "Mais nous avons un problème parce que les valeurs qui se répètent le plus sont des zéros qui sont en bas à droite de la matrice. Nous allons donc utiliser une technique appelée **ZigZag** (Entropy coding) pour réorganiser les valeurs de la matrice.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/JPEG_ZigZag.svg/220px-JPEG_ZigZag.svg.png\" alt=\"ZigZag\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple d'une partie d'une ligne de pixel sous forme de fréquence de la luminance après quantification et zigzag : \n",
      "[36, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 0, 0, 0, 0, 0, 0, 0, 37, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def zigzag(matrix):\n",
    "    zigzag_list = []\n",
    "    rows = len(matrix)\n",
    "    cols = len(matrix[0])\n",
    "\n",
    "    for i in range(rows + cols - 1):\n",
    "        if i % 2 == 0:\n",
    "            # Déterminer le point de départ de la ligne\n",
    "            if i < rows:\n",
    "                start_row, start_col = i, 0\n",
    "            else:\n",
    "                start_row, start_col = rows - 1, i - rows + 1\n",
    "            # Parcourir la ligne\n",
    "            while start_row >= 0 and start_col < cols:\n",
    "                zigzag_list.append(matrix[start_row][start_col])\n",
    "                start_row -= 1\n",
    "                start_col += 1\n",
    "        else:\n",
    "            # Déterminer le point de départ de la ligne\n",
    "            if i < cols:\n",
    "                start_row, start_col = 0, i\n",
    "            else:\n",
    "                start_row, start_col = i - cols + 1, cols - 1\n",
    "            # Parcourir la ligne\n",
    "            while start_row < rows and start_col >= 0:\n",
    "                zigzag_list.append(matrix[start_row][start_col])\n",
    "                start_row += 1\n",
    "                start_col -= 1\n",
    "\n",
    "    return zigzag_list\n",
    "\n",
    "luminance_zigzag = zigzag(luminance_quantization)\n",
    "red_zigzag = zigzag(red_quantization)\n",
    "blue_zigzag = zigzag(blue_quantization)\n",
    "print(\"Exemple d'une partie d'une ligne de pixel sous forme de fréquence de la luminance après quantification et zigzag : \")\n",
    "print(luminance_zigzag[0:50])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longueur d'exécution\n",
    "\n",
    "Nous allons maintenant utiliser la technique **Run length encoding** que nous avons vue plus tôt pour encoder les valeurs de la matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple partie d'une ligne de pixel sous forme de fréquence de la luminance après quantification, zigzag et RLE : \n",
      "[(1, 36), (1, -1), (34, 0), (1, 36), (7, 0), (1, 37), (8, 0), (1, -1), (82, 0), (1, 37), (7, 0), (1, 37), (7, 0), (1, 38), (1, 1), (7, 0), (1, -1), (27, 0), (1, -1), (110, 0), (1, 38), (7, 0), (1, 38), (7, 0), (1, 38), (7, 0), (1, 25), (1, 9), (1, -1), (6, 0), (1, 1), (7, 0), (1, -1), (27, 0), (1, -1), (7, 0), (1, -1), (150, 0), (1, 38), (7, 0), (1, 39), (7, 0), (1, 38), (7, 0), (1, 27), (7, 0), (1, 5), (1, 6), (1, -1), (6, 0)]\n"
     ]
    }
   ],
   "source": [
    "def run_length_encoding(data):\n",
    "    if not data:\n",
    "        return []\n",
    "\n",
    "    encoded_data = []\n",
    "    count = 1\n",
    "    current_value = data[0]\n",
    "\n",
    "    for i in range(1, len(data)):\n",
    "        if data[i] == current_value:\n",
    "            count += 1\n",
    "        else:\n",
    "            encoded_data.append((count, current_value))\n",
    "            count = 1\n",
    "            current_value = data[i]\n",
    "\n",
    "    # Ajouter la dernière valeur\n",
    "    encoded_data.append((count, current_value))\n",
    "\n",
    "    return encoded_data\n",
    "\n",
    "luminance_rle = run_length_encoding(luminance_zigzag)\n",
    "red_rle = run_length_encoding(red_zigzag)\n",
    "blue_rle = run_length_encoding(blue_zigzag)\n",
    "print(\"Exemple partie d'une ligne de pixel sous forme de fréquence de la luminance après quantification, zigzag et RLE : \")\n",
    "print(luminance_rle[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huffman Encoding\n",
    "\n",
    "L'encodage de Huffman est une méthode de compression de données sans perte, inventée par David A. Huffman en 1952. Cette technique est largement utilisée dans la compression de fichiers, les protocoles de transmission de données et d'autres applications où la réduction de la taille des données est nécessaire, comme le <span style=\"color: orange;\">JPEG</span>.\n",
    "\n",
    "L'idée fondamentale de l'encodage de Huffman est d'attribuer des codes binaires de longueurs variables aux symboles d'un ensemble de données, en utilisant des courts codes pour les symboles fréquents et des codes longs pour les symboles moins fréquents. Ainsi, les symboles fréquents seront représentés par moins de bits, ce qui contribue à la compression des données.\n",
    "\n",
    "Il convient de noter que bien que l'encodage de Huffman soit efficace pour des ensembles de données avec des schémas de fréquences spécifiques, il peut ne pas être optimal dans tous les cas. Pour des ensembles de données différents, d'autres méthodes de compression peuvent être plus adaptées.\n",
    "\n",
    "Voici un exemple de l'encodage de Huffman sous forme d'arbre binaire :\n",
    "\n",
    "![Huffman](./huffman.jpg)\n",
    "\n",
    "# Données dans un fichier JPEG\n",
    "\n",
    "![Meta](./meta.png)\n",
    "\n",
    "Voici comment sont stockées les données dans un fichier JPEG.\n",
    "\n",
    "Le tout premier marqueur qui nous intéresse est FF D8. Il nous indique qu'il s'agit du début de l'image. Si nous ne le voyons pas, nous pouvons supposer qu'il s'agit d'un autre fichier. Un autre marqueur tout aussi important est FF D9. Il nous indique que nous avons atteint la fin d'un fichier image. Chaque marqueur est immédiatement suivi d'un spécificateur de longueur qui donnera la longueur du segment de marqueur. Les marqueurs de début et de fin de fichier image ont toujours une longueur de deux octets chacun.\n",
    "\n",
    "Voici la liste des marqueurs qui nous sont utiles pour encoder une image JPEG :\n",
    "- 0xffd8: Le début du JPEG\n",
    "- 0xffe0: En-tête par défaut de l'application\n",
    "- 0xffdb: Définition de la table de quantification\n",
    "- 0xffc0: Début du cadre\n",
    "- 0xffc4: Définition de la table de Huffman\n",
    "- 0xffda: Début de l'analyse des numéros de balayage\n",
    "- 0xffd9: Fin du JPEG\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "En conclusion, le format de fichier JPEG (Joint Photographic Experts Group) a révolutionné la manière dont les images sont stockées, partagées et utilisées à travers le monde. Grâce à son algorithme de compression efficace, le JPEG offre une combinaison unique de qualité visuelle acceptable et de taille de fichier réduite, ce qui en fait le choix préféré pour la plupart des applications sur le web, les réseaux sociaux, le stockage d'images et bien plus encore.\n",
    "\n",
    "L'approche de compression avec perte du JPEG a permis de réduire significativement la taille des fichiers image tout en conservant une qualité visuelle souvent satisfaisante pour les utilisations courantes. Cependant, il est important de noter que cette compression peut engendrer une perte de qualité. En effet, les données supprimées ne peuvent pas être récupérées, ce qui peut entraîner une dégradation de la qualité visuelle, en particulier lorsque le taux de compression est élevé.\n",
    "\n",
    "Dans l'ensemble, le JPEG demeure un pilier essentiel dans le domaine de l'imagerie numérique, offrant une solution polyvalente pour la compression d'images, facilitant ainsi leur utilisation, leur partage et leur stockage à l'ère numérique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
