{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPEG\n",
    "## Introduction\n",
    "**J**oint **P**hotographic **E**xperts **G**roup ou **JPEG** est une norme qui définit le format d'enregistrement et l'algorithme de décodage pour une représentation numérique compressée d'une image fixe.\n",
    "La compression **JPEG** repose sur la **suppression** de **données redondantes** et **non perceptibles** dans une image.\n",
    "\n",
    "## Pourquoi est-ce intérécent de connaître comment ça fonctionnent?\n",
    "- La plus part des images de votre téléphone ou de votre caméra son enregisté dans le format JPEG.\n",
    "- environ 86% des images sur le web sont au format JPEG.\n",
    "- La plus part des vidéos utilise le principe de ce format pour être compréssée.\n",
    "\n",
    "Cette algorithme est partout dans notre vie et occupu une place importante dans celui-ci.\n",
    "\n",
    "## Globalement qu'est ce que ça fait?\n",
    "L'algorithme de compression va analyser chaque section d'une image, il va trouver et supprimer chaque pixels que nos yeux ne peuvent pas voir facilement.\n",
    "\n",
    "## Pourquoi ça marche\n",
    "Les oeils hummain ne sont pas parfait, ils ont leurs défaux. JPEG utilise ces défaux pour supprimer les informations que nos oeils on du mal à percevoir.\n",
    "Un oeils est composé de Tiges qui nous permettent de capter la luminosité mais aussi, de Cônes pour capter les couleurs (Rouge, Vers, Bleu).\n",
    "Dans chaque oeils nous avons cent million de Tiges et seulement 6 millions de Cônes.\n",
    "Nos oeils sont beacoup plus réceptif à la luminosité et à l'obscurité plus tôt que aux couleurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment ça marche ?\n",
    "### Conversion de l'espace couleur\n",
    "Une image est composé de pixels, ces pixels sont un mélange de rouge, vert et bleu allant de 0 à 255. Le mélange de ces couleur nous permet d'obtenir une couleur spécifique pour un pixel.\n",
    "\n",
    "Le processus de **conversion de l'espace couleur** prend ces trois valeurs (Rouge, Vert, Bleu) pour chaque pixel, et calcul trois nouvelle valeurs (Luminosité, Chrominance Bleu, Chrominance Rouge). Ce processus est réversible, il est appelé **YCbCr**. Durant ce processus aucune données n'est perdu, c'est juste une nouvelle façon de représenter les couleurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2289:2308:1212/142525.278754:ERROR:object_proxy.cc(577)] Failed to call method: org.freedesktop.DBus.Properties.Get: object_path= /org/freedesktop/portal/desktop: org.freedesktop.DBus.Error.InvalidArgs: L’interface « org.freedesktop.portal.FileChooser » n’existe pas\n",
      "[2289:2308:1212/142525.278799:ERROR:select_file_dialog_linux_portal.cc(285)] Failed to read portal version property\n",
      "[2289:2289:1212/142525.280919:ERROR:policy_logger.cc(156)] :components/enterprise/browser/controller/chrome_browser_cloud_management_controller.cc(161) Cloud management controller initialization aborted as CBCM is not enabled. Please use the `--enable-chrome-browser-cloud-management` command line flag to enable it if you are not using the official Google Chrome build.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouverture dans une session de navigateur existante.\n"
     ]
    }
   ],
   "source": [
    "# Ouvre le fichier image\n",
    "from PIL import Image\n",
    "\n",
    "# Ouvre le fichier image\n",
    "img = Image.open(\"image.bmp\")\n",
    "\n",
    "# Transforme l'image en tableau de pixels RGB\n",
    "pixels = img.load()\n",
    "\n",
    "# Fonction qui transforme un tuple RGB en tuple YCbCr\n",
    "def RGBtoYCbCr(RGB):\n",
    "    R, G, B = RGB\n",
    "    Y = 0.299 * R + 0.587 * G + 0.114 * B\n",
    "    Cb = -0.168736 * R - 0.331264 * G + 0.5 * B + 128\n",
    "    Cr = 0.5 * R - 0.418688 * G - 0.081312 * B + 128\n",
    "    return (Y, Cb, Cr)\n",
    "\n",
    "# Fonction qui transforme un tuple YCbCr en tuple RGB\n",
    "def YCbCrtoRGB(YCbCr):\n",
    "    Y, Cb, Cr = YCbCr\n",
    "    R = Y + 1.402 * (Cr - 128)\n",
    "    G = Y - 0.34414 * (Cb - 128) - 0.71414 * (Cr - 128)\n",
    "    B = Y + 1.772 * (Cb - 128)\n",
    "    return (R, G, B)\n",
    "\n",
    "# Affiche l'image\n",
    "img.show()\n",
    "\n",
    "# Transforme chaque pixel du tableau de de tuple RGB en tuple YCbCr\n",
    "for i in range(img.size[0]):\n",
    "    for j in range(img.size[1]):\n",
    "        YCbCr = RGBtoYCbCr(pixels[i,j])\n",
    "        pixels[i,j] = (int(YCbCr[0]), int(YCbCr[1]), int(YCbCr[2]))\n",
    "\n",
    "# Affiche l'image aprés transformation\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sous-échantillonnage de la chrominance\n",
    "Cette méthode permet par la suite de supprimer des données qui ne sont pas perceptible par nos yeux, comme nous l'avons dit plus tôt nos yeux sont movais pour detecter la couleur. Cette méthode est basé sur le fait que nos yeux sont beaucoup plus réceptif à la luminosité qu'aux couleurs.\n",
    "\n",
    "Dans cette methode nous prenons les valeurs de chrominance bleu et rouge. Par la suite nous les divisons les deux images obtenus en blocks de pixels de 2 par 2. Puis nous calculons la moyenne de chaque block pour supprimer les données redondantes pour faire en sorte que chaque valeur moyenne d'un block de 4 pixels soit la même (en occupe 1 seul). En conséquence, les informations selon lesquelles nos yeux sont incapable de percevoir sont réduites de 75%, soit 1/4 de la taille d'origine, mais la luminosité reste intacte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouverture dans une session de navigateur existante.\n",
      "Ouverture dans une session de navigateur existante.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouverture dans une session de navigateur existante.\n",
      "Ouverture dans une session de navigateur existante.\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour diviser l'image en chrominance bleue et rouge\n",
    "def extract_blue_chrominance(pixel):\n",
    "    y, cb, cr = pixel\n",
    "    return (0, cb, 0)\n",
    "\n",
    "def extract_red_chrominance(pixel):\n",
    "    y, cb, cr = pixel\n",
    "    return (0, 0, cr)\n",
    "\n",
    "def extract_luminance(pixel):\n",
    "    y, cb, cr = pixel\n",
    "    return (y, 0, 0)\n",
    "\n",
    "# Fonction pour calculer la moyenne des blocs de 2x2\n",
    "def average_block(pixels, color):\n",
    "    width, height = img.size\n",
    "    for i in range(0, width - 1, 2):\n",
    "        for j in range(0, height - 1, 2):\n",
    "            # Prendre les pixels dans un bloc de 2x2\n",
    "            block = [\n",
    "                pixels[i, j],\n",
    "                pixels[i + 1, j] if i + 1 < width else pixels[i, j],\n",
    "                pixels[i, j + 1] if j + 1 < height else pixels[i, j],\n",
    "                pixels[i + 1, j + 1] if (i + 1 < width and j + 1 < height) else pixels[i, j]\n",
    "            ]\n",
    "            # Calculer la moyenne des valeurs de chrominance dans le bloc\n",
    "            avg_cb = sum(p[1] for p in block) // len(block)\n",
    "            avg_cr = sum(p[2] for p in block) // len(block)                    \n",
    "            # Mettre à jour les images de chrominance bleue et rouge\n",
    "            if color == \"blue\":\n",
    "                for x in range(min(2, width - i)):\n",
    "                    for y in range(min(2, height - j)):\n",
    "                        blue_pixels[i + x, j + y] = (0, avg_cb, 0)\n",
    "            elif color == \"red\":\n",
    "                for x in range(min(2, width - i)):\n",
    "                    for y in range(min(2, height - j)):\n",
    "                        red_pixels[i + x, j + y] = (0, 0, avg_cr)\n",
    "\n",
    "# Créez une nouvelle image pour la chrominance bleue\n",
    "blue_chrominance = Image.new(\"YCbCr\", img.size)\n",
    "blue_pixels = blue_chrominance.load()\n",
    "\n",
    "# Créez une nouvelle image pour la chrominance rouge\n",
    "red_chrominance = Image.new(\"YCbCr\", img.size)\n",
    "red_pixels = red_chrominance.load()\n",
    "\n",
    "# Créez une nouvelle image pour la luminance\n",
    "luminance = Image.new(\"YCbCr\", img.size)\n",
    "luminance_pixels = luminance.load()\n",
    "\n",
    "# Extraire la chrominance bleue, rouge et la luminance\n",
    "for i in range(img.size[0]):\n",
    "    for j in range(img.size[1]):\n",
    "        blue_pixels[i, j] = extract_blue_chrominance(pixels[i, j])\n",
    "        red_pixels[i, j] = extract_red_chrominance(pixels[i, j])\n",
    "        luminance_pixels[i, j] = extract_luminance(pixels[i, j])\n",
    "\n",
    "# Affichage des images de chrominance bleue et rouge\n",
    "blue_chrominance.show()\n",
    "red_chrominance.show()\n",
    "\n",
    "# Moyenne des blocks de 2x2\n",
    "average_block(blue_pixels, \"blue\")\n",
    "average_block(red_pixels, \"red\")\n",
    "\n",
    "# Affichage des images de chrominance bleue et rouge aprés moyenne des block de 2x2\n",
    "blue_chrominance.show()\n",
    "red_chrominance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformée en cosinus discrète et Quantification\n",
    "\n",
    "Par la suite, ces deux étapes supprime également des informations, mais elle le font en exploitant le fait que nos yeux sont pas doués pour percevoir les éléments à hautre fréquence dans les images. Mais qu'est ce que ça veut dire ?\n",
    "\n",
    "![edge](./edge.bmp)\n",
    "\n",
    "Sur cette image de l'oreil droite du tigre, nos yeux sont capable de voir les contours de l'oreil, mais pas les détails à l'intérieur de l'oreil. C'est ce que l'on appelle les éléments à haute fréquence. Les éléments à haute fréquence sont des éléments qui changent rapidement dans une image. Les éléments à basse fréquence sont des éléments qui changent lentement dans une image. Nous allons donc utiliser cette information tromper nos yeux et supprimer les éléments à haute fréquence.\n",
    "\n",
    "La plus part des images des photographies de nature ou de paysage comportent des parties de l'image qui sont floues et la suppréssion des variations de couleurs à haute fraiquence pour créer des textures plus douces ne sont pas perceptible par nos yeux. Alors, comment l'algorithme JPEG exploite les nuance de l'oeil humain pour supprimer les éléments à haute fréquence ?\n",
    "\n",
    "L'algorithme JPEG utilise une technique appelée **Transformée en cosinus discrète** ou **DCT**. Cette technique prend un block de 8 par 8 pixels et le transforme en un tableau de 8 par 8 valeurs. Chaque valeur représente la quantité de chaque fréquence dans le block. La valeur en haut à gauche représente la fréquence la plus basse et la valeur en bas à droite représente la fréquence la plus haute. Nous enlevons 128 à chaque valeur pour que les valeurs soient comprises entre -128 et 127. -128 représente la fréquence la plus basse et 127 la fréquence la plus haute.\n",
    "\n",
    "![dct](./dct.png)\n",
    "\n",
    "Dans cette illustration de la DCT, les zones sombres représentent les basses fréquences et les zones claires les hautes fréquences. L'information relative aux hautes fréquences, souvent négligeable pour la perception humaine, est donc regroupée vers les coins de la matrice, tandis que l'information des basses fréquences, plus cruciale pour la perception, est située près du coin supérieur gauche.\n",
    "Prenons par exemple le deuxième carré en haut à gauche vers le bas. Plus la valeur de celui-ci sera haute, plus il y auras de dégradé vers la bas de blanc à noir dans l'image. Si la valeur est basse, il y aura un dégradé vers le haut de noir à blanc dans l'image. L'ensemble de ces valeurs nous permettent de reconstruire l'image.\n",
    "\n",
    "Voici la formule de la DCT:\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/e06f6ee04c9c879a283edcbb7b1fc18b86fcec5b\" alt=\"DCT\"/>\n",
    "\n",
    "u est la fréquence spatiale horizontale, pour les entiers 0 ≤ u < 8\n",
    "\n",
    "v est la fréquence spatiale verticale, pour les entiers 0 ≤ v < 8\n",
    "\n",
    "x et y sont les coordonnées horizontales et verticales du pixel, pour 0 ≤ x < 8 et 0 ≤ y < 8\n",
    "\n",
    "Le processus s'applique sur la chrominance bleu et rouge, mais aussi sur la luminosité.\n",
    "\n",
    "Il faut savoir que lorsque l'on reapplique cette formule. Nous obtenons les même valeurs que l'original. Cette formule est donc réversible.\n",
    "\n",
    "Nous allons utiliser le **DCT** pour transformer l'image de pixels en une image de fréquences. Nous allons ensuite utiliser la **Quantification** pour supprimer les fréquences que nos yeux ne peuvent pas voir facilement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple d'une ligne de de pixel sous forme de fréquence de la luminance: \n",
      "[576.0, -7.65, -1.71, 2.43, -2.0, -0.63, 0.44, 0.9, 594.62, -4.19, 1.51, -4.14, 0.38, -0.14, 0.05, -0.77, 606.25, 8.65, -11.52, 0.59, -4.0, 0.41, -0.37, -0.07, 406.75, 95.15, -11.96, 5.73, -1.25, 2.09, 1.17, 0.51, 75.37, 70.37, 9.36, 8.97, 3.88, 0.27, 0.05, 0.49, -99.0, 49.26, -5.19, 3.42, 1.5, 3.0, 0.53, 1.03, -361.12, 83.9, 2.65, 6.0, 2.12, 3.8, -1.77, 0.29, -551.75, 28.16, 1.63, 3.88, -4.75, -0.94, 0.68, 0.44, -559.0, -29.02, 7.23, -3.72, 2.0, -2.1, -0.83, 1.04, -291.5, -124.33, 4.18, -7.56, 3.5, 0.21, 7.47, -1.16, 129.37, -85.19, -45.69, 5.59, -11.87, 0.56, -6.11, -1.25, 91.5, -93.1, 73.4, 17.74, 13.5, 2.74, 0.17, 0.43, 162.75, 129.27, -3.55, -7.41, -3.25, -0.87, -5.3, 0.33, -64.87, 3.4, 7.6, 7.21, 2.37, -0.04, 1.04, -0.56, -76.62, 22.93, -5.84, 1.39, -3.37, 0.11, -5.29, -0.1, -251.87, 58.88, 7.66, 11.43, -1.38, 6.8, -6.01, 0.19, -533.5, 29.93, 43.31, 7.69, 8.75, -0.3, -0.62, 0.62, -429.87, -1.82, -23.8, -7.71, -5.88, -2.76, -0.29, -0.86, -462.25, -4.82, 13.79, -10.3, 3.25, -2.9, -0.03, 0.25, -165.37, -141.04, -13.07, 7.4, -6.62, 2.82, 0.14, -1.02, -31.12, -9.0, 8.32, 2.05, 2.37, 4.5, -1.15, 0.14, 37.87, -74.51, 26.53, 5.67, -0.38, -2.86, -0.3, -0.27, 151.75, 76.68, -58.99, 21.21, -11.5, 5.98, -5.87, 0.02, -289.75, 33.4, 21.18, 5.87, 11.0, 0.74, 4.76, -1.11, -201.75, -34.86, -10.87, -6.17, -3.5, -3.47, -0.1, -0.61, -166.25, 4.79, 0.37, -3.32, -2.0, -3.36, -0.42, -0.37, -254.0, 49.6, 4.13, -2.71, 3.5, 0.61, 0.18, -0.34, -261.12, -9.06, 1.74, -11.98, -2.13, -2.78, -0.04, -0.62, -68.12, -88.56, 1.57, -6.75, 0.12, -3.53, 0.84, 0.16, 250.5, -78.8, -10.67, -6.24, 4.25, -0.09, 0.36, -1.04, 404.62, -2.23, -6.09, -5.09, -1.37, -3.62, 1.3, -0.26, 412.37, 63.17, -27.86, 5.08, -2.62, -5.87, -6.18, 0.03, 179.62, 35.84, 8.34, 0.47, -0.12, 2.78, 0.2, 0.2, 112.25, -2.77, 16.94, -2.67, 3.75, -2.63, -0.25, 0.17, 315.25, -108.18, 4.3, -4.32, 0.0, 2.48, 5.8, 0.69, 542.25, -9.57, -14.89, 1.7, -6.75, -1.5, -6.55, -0.18, 507.25, 4.83, 10.31, 5.35, 0.25, 1.35, 0.06, -0.21, 570.12, -28.01, 0.18, -1.15, -1.12, -3.37, 1.41, -0.56, 641.5, -4.28, -7.72, -3.76, 3.75, -1.46, -4.92, 0.04, 662.5, -2.39, -0.0, 2.3, -4.0, 0.3, -0.0, -0.44, 673.62, 1.73, -3.84, -0.26, -2.87, -0.9, -0.44, 0.45, 443.87, 299.75, -223.25, 118.19, -35.87, -2.27, 11.43, -8.89, -610.5, 14.86, 4.62, 7.68, 2.25, 2.79, 5.93, 0.61, -632.5, 1.3, -2.37, -1.97, 4.0, -0.07, 0.17, 0.23, -633.75, -1.0, 2.33, -0.62, 3.5, -1.2, 0.39, 0.22, -139.0, -496.04, 144.71, 56.12, -67.0, 15.68, 10.96, -8.29, 608.25, -2.49, 8.0, -0.76, -4.5, -3.86, -6.83, -0.45, 643.87, -5.67, -9.3, -1.91, -1.62, 0.41, 0.74, 1.02, 647.12, 5.89, 0.03, -1.81, 2.13, -0.54, 0.39, -0.42, 651.75, 1.53, -6.5, -3.6, -0.25, 0.07, -0.01, 0.24, 633.75, 4.93, -11.95, 6.27, -1.75, 0.3, 5.76, 0.2, 603.12, -2.78, 2.66, -0.06, 0.13, 0.56, -0.43, -0.04, 594.5, 4.75, 3.94, 4.17, 6.0, -2.44, -0.28, -0.24, 590.0, -0.77, 2.26, 4.12, -1.25, 0.21, 6.1, 0.22, 603.75, -6.94, 2.37, 4.76, -0.25, 0.54, -0.17, 0.35, 75.62, 104.89, 98.81, 88.93, 75.62, 59.42, 40.93, 20.86]\n",
      "PS: Nous avons arrondis les valeurs pour une meilleur lisibilité\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "luminance_minus_128 = []\n",
    "blue_minus_128 = []\n",
    "red_minus_128 = []\n",
    "\n",
    "# Soustraction de 128 pour chaque pixel\n",
    "for i in range(img.size[0]):\n",
    "    luminance_minus_128.append([])\n",
    "    blue_minus_128.append([])\n",
    "    red_minus_128.append([])\n",
    "    for j in range(img.size[1]):\n",
    "        luminance_minus_128[i].append(luminance_pixels[i, j][0] - 128)\n",
    "        blue_minus_128[i].append(blue_pixels[i, j][1] - 128)\n",
    "        red_minus_128[i].append(red_pixels[i, j][2] - 128)\n",
    "\n",
    "# Fonction pour calculer le coefficient alpha\n",
    "def alpha(u):\n",
    "    return 1 / math.sqrt(2) if u == 0 else 1\n",
    "\n",
    "# Appliquer la transformation en cosinus discret (DCT) sur un bloc de 8x8\n",
    "def apply_dct(block):\n",
    "    dct_block = [[0 for _ in range(8)] for _ in range(8)]  # Initialisation d'une matrice pour stocker les résultats de la DCT\n",
    "    for x in range(8):\n",
    "        for y in range(8):\n",
    "            sum_val = 0\n",
    "            # Calcul de la DCT pour chaque élément du bloc 8x8\n",
    "            for i in range(8):\n",
    "                for j in range(8):\n",
    "                    sum_val += block[i][j] * math.cos(((2 * i + 1) * x * math.pi) / 16) * math.cos(((2 * j + 1) * y * math.pi) / 16)\n",
    "            # Stockage du résultat dans la matrice de la DCT après l'application des coefficients alpha\n",
    "            dct_block[x][y] = round(sum_val * (1 / 4 * alpha(x) * alpha(y)), 2)\n",
    "    return dct_block\n",
    "\n",
    "# Appliquer la transformation en cosinus discret (DCT) sur toute la matrice\n",
    "def discrete_cosine_transform(matrix):\n",
    "    width = len(matrix)\n",
    "    height = len(matrix[0])\n",
    "\n",
    "    dct = []  # Initialisation d'une liste pour stocker les blocs DCT\n",
    "    for u in range(0, width, 8):\n",
    "        dct.append([])\n",
    "        for v in range(0, height, 8):\n",
    "            # Création de blocs 8x8 à partir de la matrice d'entrée\n",
    "            block = [[matrix[x][y] if x < width and y < height else 0 for y in range(v, v + 8)] for x in range(u, u + 8)]\n",
    "            # Application de la DCT sur chaque bloc 8x8\n",
    "            dct_block = apply_dct(block)\n",
    "            # Stockage du bloc DCT dans la liste\n",
    "            dct[-1].append(dct_block)\n",
    "\n",
    "    # Réorganisation des coefficients DCT dans une seule liste\n",
    "    dct = [[dct[u][v][x][y] for v in range(len(dct[u])) for y in range(8)] for u in range(len(dct)) for x in range(8)]\n",
    "    return dct\n",
    "\n",
    "            \n",
    "\n",
    "# DCT de la luminance\n",
    "luminance_dct = discrete_cosine_transform(luminance_minus_128)\n",
    "# DCT de la chrominance bleue\n",
    "blue_dct = discrete_cosine_transform(blue_minus_128)\n",
    "# DCT de la chrominance rouge\n",
    "red_dct = discrete_cosine_transform(red_minus_128)\n",
    "\n",
    "print(\"Exemple d'une ligne de de pixel sous forme de fréquence de la luminance: \")\n",
    "print(luminance_dct[0])\n",
    "print(\"PS: Nous avons arrondis les valeurs pour une meilleur lisibilité\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ce stade, nous avons créé une variable qui représente les valeurs du dct sous forme matricielle pour chaque chrominance et luminosité.\n",
    "\n",
    "Maintenant nous devons appliquer la **Quantification** sur les valeurs du dct pour chaque chrominance et luminosité.\n",
    "La **Quantification** est une technique qui permet de supprimer les fréquences que nos yeux ne peuvent pas voir facilement.\n",
    "\n",
    "Il existe plusieur matrice pour la **Quantification**. Ces matrices déffinisent le niveau de compression de l'image. Plus cette matrice va permettre d'avoir des 0, plus l'image sera compressée, et moins la qualité de l'image sera bonne.\n",
    "\n",
    "Voici la matrice qui permet de faire une compression de 50% comme fournis par la norme JPEG:\n",
    "\n",
    "| 16 | 11 | 10 | 16 | 24 | 40 | 51 | 61 |\n",
    "|----|----|----|----|----|----|----|----|\n",
    "| 12 | 12 | 14 | 19 | 26 | 58 | 60 | 55 |\n",
    "| 14 | 13 | 16 | 24 | 40 | 57 | 69 | 56 |\n",
    "| 14 | 17 | 22 | 29 | 51 | 87 | 80 | 62 |\n",
    "| 18 | 22 | 37 | 56 | 68 | 109 | 103 | 77 |\n",
    "| 24 | 35 | 55 | 64 | 81 | 104 | 113 | 92 |\n",
    "| 49 | 64 | 78 | 87 | 103 | 121 | 120 | 101 |\n",
    "| 72 | 92 | 95 | 98 | 112 | 100 | 103 | 99 |\n",
    "\n",
    "Pour effectuer le **Quantification** nous prenons toujours de block de 8 par 8 pixels. Nous divisons les valeurs du dct par les valeurs de la matrice de **Quantification**. Nous arrondissons les valeurs obtenues à l'entier le plus proche. Nous obtenons ainsi une nouvelle matrice de 8 par 8 valeurs. Nous allons ensuite utiliser cette matrice pour reconstruire l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple d'une ligne de de pixel sous forme de fréquence de la luminance aprés quantification: \n",
      "[36, -1, 0, 0, 0, 0, 0, 0, 37, 0, 0, 0, 0, 0, 0, 0, 38, 1, -1, 0, 0, 0, 0, 0, 25, 9, -1, 0, 0, 0, 0, 0, 5, 6, 1, 1, 0, 0, 0, 0, -6, 4, -1, 0, 0, 0, 0, 0, -23, 8, 0, 0, 0, 0, 0, 0, -34, 3, 0, 0, 0, 0, 0, 0, -35, -3, 1, 0, 0, 0, 0, 0, -18, -11, 0, 0, 0, 0, 0, 0, 8, -8, -5, 0, 0, 0, 0, 0, 6, -8, 7, 1, 1, 0, 0, 0, 10, 12, 0, 0, 0, 0, 0, 0, -4, 0, 1, 0, 0, 0, 0, 0, -5, 2, -1, 0, 0, 0, 0, 0, -16, 5, 1, 1, 0, 0, 0, 0, -33, 3, 4, 0, 0, 0, 0, 0, -27, 0, -2, 0, 0, 0, 0, 0, -29, 0, 1, -1, 0, 0, 0, 0, -10, -13, -1, 0, 0, 0, 0, 0, -2, -1, 1, 0, 0, 0, 0, 0, 2, -7, 3, 0, 0, 0, 0, 0, 9, 7, -6, 1, 0, 0, 0, 0, -18, 3, 2, 0, 0, 0, 0, 0, -13, -3, -1, 0, 0, 0, 0, 0, -10, 0, 0, 0, 0, 0, 0, 0, -16, 5, 0, 0, 0, 0, 0, 0, -16, -1, 0, -1, 0, 0, 0, 0, -4, -8, 0, 0, 0, 0, 0, 0, 16, -7, -1, 0, 0, 0, 0, 0, 25, 0, -1, 0, 0, 0, 0, 0, 26, 6, -3, 0, 0, 0, 0, 0, 11, 3, 1, 0, 0, 0, 0, 0, 7, 0, 2, 0, 0, 0, 0, 0, 20, -10, 0, 0, 0, 0, 0, 0, 34, -1, -1, 0, 0, 0, 0, 0, 32, 0, 1, 0, 0, 0, 0, 0, 36, -3, 0, 0, 0, 0, 0, 0, 40, 0, -1, 0, 0, 0, 0, 0, 41, 0, 0, 0, 0, 0, 0, 0, 42, 0, 0, 0, 0, 0, 0, 0, 28, 27, -22, 7, -1, 0, 0, 0, -38, 1, 0, 0, 0, 0, 0, 0, -40, 0, 0, 0, 0, 0, 0, 0, -40, 0, 0, 0, 0, 0, 0, 0, -9, -45, 14, 4, -3, 0, 0, 0, 38, 0, 1, 0, 0, 0, 0, 0, 40, -1, -1, 0, 0, 0, 0, 0, 40, 1, 0, 0, 0, 0, 0, 0, 41, 0, -1, 0, 0, 0, 0, 0, 40, 0, -1, 0, 0, 0, 0, 0, 38, 0, 0, 0, 0, 0, 0, 0, 37, 0, 0, 0, 0, 0, 0, 0, 37, 0, 0, 0, 0, 0, 0, 0, 38, -1, 0, 0, 0, 0, 0, 0, 5, 10, 10, 6, 3, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "quantization_table_fifty_percent = [\n",
    "    [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "    [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "    [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "    [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "    [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "    [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "    [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "    [72, 92, 95, 98, 112, 100, 103, 99]\n",
    "]\n",
    "\n",
    "def quantize(dct, quantization_table):\n",
    "    quantized_dct = []\n",
    "    for i in range(len(dct)):\n",
    "        quantized_dct.append([])\n",
    "        for j in range(len(dct[i])):\n",
    "            # Division de chaque coefficient DCT par le coefficient de quantification correspondant\n",
    "            quantized_dct[i].append(round(dct[i][j] / quantization_table[i % 8][j % 8]))\n",
    "    return quantized_dct\n",
    "\n",
    "luminance_quantization = quantize(luminance_dct, quantization_table_fifty_percent)\n",
    "blue_quantization = quantize(blue_dct, quantization_table_fifty_percent)\n",
    "red_quantization = quantize(red_dct, quantization_table_fifty_percent)\n",
    "\n",
    "print(\"Exemple d'une ligne de de pixel sous forme de fréquence de la luminance aprés quantification: \")\n",
    "print(luminance_quantization[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez voir que les valeurs de la matrice de **Quantification** sont plus grandes dans les coins supérieurs gauche et plus petites dans les coins inférieurs droits. Cela signifie que les fréquences basses sont plus susceptibles d'être conservées que les fréquences élevées. Cela permet donc de supprimer de l'information que nos yeux ne peuvent pas voir facilement.\n",
    "\n",
    "Nous allons par la suite pouvoir facilement recoder cette image en marquant non pas chaque case de la matrice mais plus tôt les cases de la matrice et combien de fois elles se répètent. (Run length encoding)\n",
    "\n",
    "Exemple:\n",
    "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1] => (1, 10) car 1 se répète 10 fois.\n",
    "\n",
    "Mais nous avons un problème car les valeurs qui ce répètent le plus sont des 0 qui sont en bas à droite de la matrice. Nous allons donc utiliser une technique appelée **ZigZag** (Entropy coding) pour réorganiser les valeurs de la matrice.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/JPEG_ZigZag.svg/220px-JPEG_ZigZag.svg.png\" alt=\"ZigZag\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple d'une ligne de pixel sous forme de fréquence de la luminance après quantification et zigzag : \n",
      "[36, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 0, 0, 0, 0, 0, 0, 0, 37, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def zigzag(matrix):\n",
    "    zigzag_list = []\n",
    "    rows = len(matrix)\n",
    "    cols = len(matrix[0])\n",
    "\n",
    "    for i in range(rows + cols - 1):\n",
    "        if i % 2 == 0:\n",
    "            # Déterminer le point de départ de la ligne\n",
    "            if i < rows:\n",
    "                start_row, start_col = i, 0\n",
    "            else:\n",
    "                start_row, start_col = rows - 1, i - rows + 1\n",
    "            # Parcourir la ligne\n",
    "            while start_row >= 0 and start_col < cols:\n",
    "                zigzag_list.append(matrix[start_row][start_col])\n",
    "                start_row -= 1\n",
    "                start_col += 1\n",
    "        else:\n",
    "            # Déterminer le point de départ de la ligne\n",
    "            if i < cols:\n",
    "                start_row, start_col = 0, i\n",
    "            else:\n",
    "                start_row, start_col = i - cols + 1, cols - 1\n",
    "            # Parcourir la ligne\n",
    "            while start_row < rows and start_col >= 0:\n",
    "                zigzag_list.append(matrix[start_row][start_col])\n",
    "                start_row += 1\n",
    "                start_col -= 1\n",
    "\n",
    "    return zigzag_list\n",
    "\n",
    "luminance_zigzag = zigzag(luminance_quantization)\n",
    "red_zigzag = zigzag(red_quantization)\n",
    "blue_zigzag = zigzag(blue_quantization)\n",
    "print(\"Exemple d'une partie d'une ligne de pixel sous forme de fréquence de la luminance après quantification et zigzag : \")\n",
    "print(luminance_zigzag[0:50])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longueur d'exécution et codage de Huffman\n",
    "\n",
    "Nous allons maintenant utiliser la technique **Run length encoding** pour encoder les valeurs de la matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple d'une ligne de pixel sous forme de fréquence de la luminance après quantification, zigzag et RLE : \n",
      "[(1, 36), (1, -1), (34, 0), (1, 36), (7, 0), (1, 37), (8, 0), (1, -1), (82, 0), (1, 37), (7, 0), (1, 37), (7, 0), (1, 38), (1, 1), (7, 0), (1, -1), (27, 0), (1, -1), (110, 0), (1, 38), (7, 0), (1, 38), (7, 0), (1, 38), (7, 0), (1, 25), (1, 9), (1, -1), (6, 0), (1, 1), (7, 0), (1, -1), (27, 0), (1, -1), (7, 0), (1, -1), (150, 0), (1, 38), (7, 0), (1, 39), (7, 0), (1, 38), (7, 0), (1, 27), (7, 0), (1, 5), (1, 6), (1, -1), (6, 0)]\n"
     ]
    }
   ],
   "source": [
    "def run_length_encoding(data):\n",
    "    if not data:\n",
    "        return []\n",
    "\n",
    "    encoded_data = []\n",
    "    count = 1\n",
    "    current_value = data[0]\n",
    "\n",
    "    for i in range(1, len(data)):\n",
    "        if data[i] == current_value:\n",
    "            count += 1\n",
    "        else:\n",
    "            encoded_data.append((count, current_value))\n",
    "            count = 1\n",
    "            current_value = data[i]\n",
    "\n",
    "    # Ajouter la dernière valeur\n",
    "    encoded_data.append((count, current_value))\n",
    "\n",
    "    return encoded_data\n",
    "\n",
    "luminance_rle = run_length_encoding(luminance_zigzag)\n",
    "red_rle = run_length_encoding(red_zigzag)\n",
    "blue_rle = run_length_encoding(blue_zigzag)\n",
    "print(\"Exemple d'une ligne de pixel sous forme de fréquence de la luminance après quantification, zigzag et RLE : \")\n",
    "print(luminance_rle[0:50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
